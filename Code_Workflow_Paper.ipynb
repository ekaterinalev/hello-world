{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using cross-location and cross-domain corpora for emotion classification of tweets about museum experiences \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tweepy package, collecting data from Twitter API with New York City museums' mentions (@) and hashtags (#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "\n",
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "import json \n",
    "import pandas\n",
    "import nltk\n",
    "import from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Accessing Twitter API using information in a created Twitter Apps which provides access tokens: https://apps.twitter.com/\n",
    "\n",
    "consumer_key = 'xxxxxxxxxxxx' \n",
    "consumer_secret = 'xxxxxxxxxxxxx' \n",
    "access_token = 'xxxxxxxxxxxx' \n",
    "access_secret = 'xxxxxxxxxxxx' \n",
    "auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "auth.set_access_token(access_token, access_secret) \n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser()) # Using JSON Parser to read the Twitter formatting\n",
    "\n",
    "# Reference link: http://www.tweepy.org/\n",
    "# Reference link: https://stackoverflow.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating lists with 130 New York City museums' Twitter handles and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handles_list = ['@iAliceAusten','@americanacad','@FolkArtMuseum','@EllisIsland','@AMNH','@ANSCoins','@Visual_ArtsAS','@AnneFrankCenter',\n",
    "                '@AsiaSociety','@NYCAudubon','@Bartow_Pell','@BowneHouse1','@BronxHistory','@BronxMuseum','@BrooklynKids','@brooklynhistory',\n",
    "                '@brooklynmuseum','@ChelseaArtMus','@cmomNYC','@CMAinNYC','@met_cloisters','@coneyislandusa','@cooperhewitt','@DaheshShop',\n",
    "                '@DiaFoundation','@DiscoveryTS','@drawingcenter','@DyckmanFarm','@elmuseo','@frauncestavern','@frickcollection',\n",
    "                '@GI_NewYork','@gracie_mansion','@HSAmuseum','@HolocaustTolCtr','@MuseumBarge','@ICPhotog','@ICPlibrary',\n",
    "                '@ICPStore','@IntrepidMuseum','@NoguchiMuseum','@IAMMuseumNYC','@TibetanMuseum','@TheJewishMuseum',\n",
    "                '@nycwax','@MerchantsHouse','@metmuseum','@MCINY','@MorganLibrary','@MorrisJumel','@MuseumMVH','@MASNYC',\n",
    "                '@FinanceMuseum','@MADMuseum','@mocanyc','@MoCADA','@MJHnews','@MuseumModernArt','@MuseumofCityNY',\n",
    "                '@MovingImageNYC','@NatlAcademy','@AmerIndianNYC','@Sept11Memorial','@NeueGalerieNY','@newmuseum','@FDNYMuseum',\n",
    "                '@nycpolicemuseum','@nysci','@NYHistory','@NYTransitMuseum','@OSHBklyn','@MoMAPS1','@paleycenter',\n",
    "                '@QueensMuseum','@RubinMuseum','@ScanHouse','@SchomburgCenter','@SVAgalleries','@SkyMuseum','@Guggenheim',\n",
    "                '@SonySquareNYC','@SeaportMuseum','@SIMuseum','@studiomuseum','@tenementmuseum','@NatlJazzMuseum','@museumatFIT',\n",
    "                '@TRBirthplaceNPS','@UkrMuseum','@WaveHill','@whitneymuseum','@WyckoffMuseum','@lbinyc','@AmericanSephard',\n",
    "                '@yivoinstitute','@AJHSNYC','@YUMuseum','@cjewishhistory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtag_list = ['#iAliceAusten','#americanacad','#FolkArtMuseum','#EllisIsland','#AMNH','#ANSCoins','#Visual_ArtsAS','#AnneFrankCenter',\n",
    "                '#AsiaSociety','#NYCAudubon','#Bartow_Pell','#BowneHouse1','#BronxHistory','#BronxMuseum','#BrooklynKids','#brooklynhistory',\n",
    "                '#brooklynmuseum','#ChelseaArtMus','#cmomNYC','#CMAinNYC','#met_cloisters','#coneyislandusa','#cooperhewitt','#DaheshShop',\n",
    "                '#DiaFoundation','#DiscoveryTS','#drawingcenter','#DyckmanFarm','#elmuseo','#frauncestavern','#frickcollection',\n",
    "                '#GI_NewYork','#gracie_mansion','#HSAmuseum','#HolocaustTolCtr','#MuseumBarge','#ICPhotog','#ICPlibrary',\n",
    "                '#ICPStore','#IntrepidMuseum','#NoguchiMuseum','#IAMMuseumNYC','#TibetanMuseum','#TheJewishMuseum',\n",
    "                '#nycwax','#MerchantsHouse','#metmuseum','#MCINY','#MorganLibrary','#MorrisJumel','#MuseumMVH','#MASNYC',\n",
    "                '#FinanceMuseum','#MADMuseum','#mocanyc','#MoCADA','#MJHnews','#MuseumModernArt','#MuseumofCityNY',\n",
    "                '#MovingImageNYC','#NatlAcademy','#AmerIndianNYC','#Sept11Memorial','#NeueGalerieNY','#newmuseum','#FDNYMuseum',\n",
    "                '#nycpolicemuseum','#nysci','#NYHistory','#NYTransitMuseum','#OSHBklyn','#MoMAPS1','#paleycenter',\n",
    "                '#QueensMuseum','#RubinMuseum','#ScanHouse','#SchomburgCenter','#SVAgalleries','#SkyMuseum','#Guggenheim',\n",
    "                '#SonySquareNYC','#SeaportMuseum','#SIMuseum','#studiomuseum','#tenementmuseum','#NatlJazzMuseum','#museumatFIT',\n",
    "                '#TRBirthplaceNPS','#UkrMuseum','#WaveHill','#whitneymuseum','#WyckoffMuseum','#lbinyc','#AmericanSephard',\n",
    "                '#yivoinstitute','#AJHSNYC','#YUMuseum','#cjewishhistory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_for_df_status = [] # Creating empty list for status data \n",
    "for parameter in handles_list: # Iterating through a list of 130 museum handles (for hashtags, use hashtag_list) \n",
    "    tweets = api.search(parameter) # Specifying query parameter which is a Twitter handle or hashtag\n",
    "    text = json.dumps(tweets) # Loading tweet content \n",
    "    json_file = json.loads(text) \n",
    "    for i in json_file['statuses']: # Extracting status of tweets \n",
    "        status = i['text']  \n",
    "        list_for_df_status.append(status) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optional: saving results to a .csv filee\n",
    "\n",
    "data = pandas.DataFrame(list_for_df_status, columns=['status'])\n",
    "data.to_csv('Sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "\n",
    "import nltk\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing text file for analysis and creating a list\n",
    "\n",
    "text = []\n",
    "with open('Train_text.csv', encoding=\"latin-1\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for i in reader:\n",
    "        text.append(i[0])\n",
    "\n",
    "# Reference link: https://stackoverflow.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing file with associated labels\n",
    "\n",
    "labels = []\n",
    "with open('Train_labels.csv', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for i in reader:\n",
    "        labels.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a test file with text\n",
    "\n",
    "text_list = []\n",
    "with open('Test_text.csv', encoding='latin-1') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for i in reader:\n",
    "        text_list.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing file with associated labels for test\n",
    "\n",
    "labels_test = []\n",
    "with open('Test_labels.csv', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for i in reader:\n",
    "        labels_test.append(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating text pre-processing, defining metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "# Reference link: http://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metrics(y_test, y_predicted):  \n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                     average='weighted')             \n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Reference link: https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating term frequency-inverse document frequency matrix for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf(data):\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer=LemmaTokenizer())\n",
    "    train = tfidf_vectorizer.fit_transform(data)\n",
    "    return train, tfidf_vectorizer\n",
    "\n",
    "X_train, tfidf_vectorizer = tfidf(text)\n",
    "X_test = tfidf_vectorizer.transform(text_list)\n",
    "\n",
    "# Reference link: https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running classifier: Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X_train, labels_ready)\n",
    "y_predicted = clf.predict(X_test)\n",
    "\n",
    "y_test = labels_ready_test\n",
    "accuracy, precision, recall, f1 = metrics(y_test, y_predicted)\n",
    "print(\"accuracy = %.2f, precision = %.2f, recall = %.2f, f1 = %.2f\" % (accuracy, precision, \n",
    "                                                                       recall, f1))\n",
    "\n",
    "# Reference link: https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = ['angry', 'disgust','happy','sad','surprise']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Name')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Reference link: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running classifier: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, labels_ready)\n",
    "\n",
    "y_test = labels_ready_test\n",
    "y_predicted = clf.predict(X_test)\n",
    "\n",
    "accuracy, precision, recall, f1 = metrics(y_test, y_predicted)\n",
    "print(\"accuracy = %.2f, precision = %.2f, recall = %.2f, f1 = %.2f\" % (accuracy, precision, \n",
    "                                                                       recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Name')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Reference link: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "### 1. Tweepy package: http://www.tweepy.org/\n",
    "### 2. Emmanuel Ameisen. How to solve 90% of NLP problems: a step-by-step guide.\n",
    "###  https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb\n",
    "### 3. Sklearn package:\n",
    "### http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "### http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "### 4. Stackoverflow: https://stackoverflow.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
